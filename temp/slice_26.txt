中
可能遇到的很多事也会影响他的工作表现，而这些事都是人们在当下无法预测的，就算是世界上最好的预测模型也无法预
测，这种难以解决的不确定性包括所有与你的预测有关但当下
无法得知的信息。
此外，与应聘者有关的很多事情从原则上说应该是可以知
道的，但你在做判断时并不知道。对我们的目的而言，不管这
种知识上的差距是源于缺少足够的预测性测试，还是由于获取
更多信息的成本过高，抑或是由于你自己的调查疏忽，都无关
紧要，不管是哪个原因，你都处于信息不完备的状态中。
难以琢磨的不确定性（未知之事）和不完备的信息（可知
但不知之事）都将使完美预测变得不可能。这些未知信息并非
源于判断中的偏差或噪声，而是源于任务本身的客观特征。这
种由于重要信息缺失而产生的客观无知严重限制了人们判断的
准确性，为避免用词太过专业，我们用“无知”来指代这种不
确定性。这样可以避免混淆“不确定性”和“噪声”。不确定
性是关于世界和未来的，噪声是本应相同的判断中出现的变
异。
在某些情况下，我们能获得的信息比另外一些情况下更
多，而且客观无知更少。此时，大多数专业判断的表现都是非
常不错的。例如，医生可以对很多疾病做出准确的诊断，律师
在面对法律纠纷时可以准确地判断法官的判决结果。
但是，一般而言，你仍然可以想象到，从事预测性工作的
人还是会低估自身的客观无知。过度自信是已经被大量研究证
明了的一种认知偏差。具体而言，人们往往会过度高估自己做出准确预测的能力，即使是在信息有限的条件下。我们所讲的
预测性判断中的噪声也可以被称为客观无知， 哪 里 有 预 测 ， 哪
里 就 有 客 观 无 知 ， 而 且 客 观 无 知 比 你 想 象 的 要 严 重 得 多 。
异 常 自 信 的 权 威 ： 准 确 性和 黑 猩 猩 扔 飞 镖 差 不 多
心理学家菲利普·泰特洛克是我们的好朋友，他是一个坚
持真理且充满幽默感的人。2005年，他出版了《专家的政治判
断》（ Expert Political Judgment ）一书。书名听起来是中性
的，但实际上这本书对专家预测政治事件的能力进行了猛烈抨
击。
泰特洛克研究了近300位专家的预测，包括著名的记者、受
人尊敬的学者以及国家领导人的高级智囊团等。他想验证这些
人的政治、经济和社会性预测是否正确，这项研究持续了20年
之久。可见，想要验证长期性预测是否正确，你必须有足够的
耐心。
泰特洛克的主要发现是：这些所谓的专家在对重大政治事
件进行预测时表现得非常糟糕。书中有句玩笑话很有名：“整
体上，普通专家预测的准确性和黑猩猩扔飞镖差不多。”更精
确地说，那本书的核心内容是：那些以“对政治和经济趋势发
表评论或提供建议”谋生的专家，他们“在‘展望’新趋势
时，做得并不比《纽约时报》的记者或细心的读者好”。可以
肯定的是，专家们讲故事的能力很强，他们可以分析形势，并
用令人信服的方式来描绘事态的发展趋势，并满怀信心地在演播室里反驳那些提出反对意见的人，但是他们真的知道会发生
什么事吗？事实上，他们可能并不知道。
泰特洛克撕开了专家们的面具，并得出了上述结论。对于
每个预测性问题，他都要求专家给出三种结果（维持现状、很
可能发生或不大可能发生）的对应概率。在理想情况下，即使
让一只黑猩猩通过扔飞镖的方式进行选择，它都会以相同的概
率（1/3）“选中”三个结果中的任意一个。泰特洛克发现，专
家们预测的准确率并不比这一最低标准好多少。平均而言，他
们评估那些未来真正发生了的事件时，给出的概率只比那些最
终没有发生的事件稍微高一点，但他们常常表现得异常自信。
那些对世界该如何运转拥有一套清晰理论的权威人士是最自信
的，也是最不可靠的。
泰特洛克的发现表明，对具体事件进行详细的、长期性的
预测根本不可能。这个世界是混乱的，一些微不足道的小事都
可能引发严重的后果。例如，在受孕的瞬间，历史上的每个重
要人物以及无关紧要的人物都有50%的可能性会以另一种性别出
生。那样一来，注定会发生不可预见的事件，而且这些不可预
见的事件的后果也是不可预见的。因此，你对未来的展望越
远，客观无知就积累得越多。专家们在政治判断上的局限性并
非源于预测者的认知局限，而是由他们对未来的客观无知所决
定的。因此，我们的结论是： 不 应 该 将 专 家 失 败 的 预 测 归咎 于
专 家 本 人 。 但 是 ， 他 们 确 实 应 该受 到 批 评 ， 因 为 他 们 在 尝 试 完
成 一 项 不可 能 完 成 的 任 务 ， 却 相 信 自 己可 以 做 到 。泰特洛克还有一项令人震惊的发现： 长 期 预 测 毫 无 用 处 。
几年后，他与妻子芭芭拉·梅勒斯（Barbara Mellers）合作，
研究了人们在相对较短的时间内（通常不到一年）对事件进行
预测的情况。他们发现：短期预测是困难的，但并非不可能，
而且有些人始终比大多数人（包括情报界的专业人士）预测得
好。泰特洛克和梅勒斯将这些人称为“超级预测者”
（superforecasters ）。在我们看来，客观无知会随着我们对
未来展望的深入而增多，他们的新发现恰恰与这一观点相符。
我们将在第21章中继续讨论超级预测者。
人 的 判 断 很 糟 糕 ， 但 模 型 也 不 尽 如 人 意
泰特洛克的早期研究表明，对于时间跨度较大的政治预
测，人们往往是无能为力的。要想证明一项任务是不可能完成
的，只有在很多可靠的参与者尝试了该任务并且都失败了的情
况下才能做到，时间跨度较大的政治预测便是如此。我们已经
给大家展示过，对信息进行机械性汇总的结果通常比人类的判
断更优。由于在预测方面的准确性，规则和算法能够更好地验
证某些结果能否真正被预测。
前面的章节可能会让你形成一种印象，即算法在进行预测
性判断时具有压倒性的优势，但是你有这种印象可能是被误导
了。 模 型 确 实 比 人 表 现 得 更 好 ， 但 并 没 有 好 很 多 。没有证据表
明，在依据相同的信息进行预测时，人类表现得非常差而模型
却表现得非常好。在第9章，我们提到有一篇报告对136项研究进行了回顾，
这些研究表明机械性的整合优于诊断性判断。尽管这种优势的
确是“大规模且一致的”，但两者的表现差距并不大。该报告
中有93项研究关注的是二选一的决策问题，它们衡量了临床医
生和公式的“命中率”。总体来说，临床医生有68%的预测是正
确的，而公式有73%的预测是正确的。报告中另有35项研究用相
关系数来衡量预测的准确性。这些研究发现，临床医生的判断
与真实结果的平均相关系数为0.3（PC=60%），而公式预测的相
关系数是0.56（PC=69%）。在这两个指标上，公式总是比临床
医生预测得好，但是机械性预测的有效性依然有限，使用模型
并不能改变相当低的预测性的上限。
人工智能的预测性如何呢？正如前文所述，人工智能通常
要比简单模型表现得好，但在大多数情况下，它的表现远称不
上完美。例如，请回想一下我们在第10章中讨论过的保释预测
算法，我们发现，被拒绝保释的人数如果保持不变，该算法可
以将犯罪率降低24%，相比于法官所做的预测，这是一个较大幅
度的改进。但是，如果该算法可以准确地预测哪些被告会再次
犯罪的话，它就能更大幅度地降低犯罪率。对未来将发生的犯
罪行为进行预测是一种超自然的能力，它只存在于《少数派报
告》（ Minority Report ）这种科幻小说中，因为对人类行为进
行预测要面临大量的客观无知。
由塞德希尔·穆来纳森和齐亚德·欧博迈亚（Ziad
Obermeyer ）完成的另一项研究对心脏病诊断进行了建模。当患
者有心脏病突发的迹象时，急诊医生必须决定是否需要进行额外的检查。原则上，仅当患者心脏病突发的风险足够高时才应
进行额外的检查——这些检查不仅昂贵，而且有一定的风险性
和侵害性。低风险患者无须进行额外的检查。因此，医生在决
定是否开检查单时需要先评估患者心脏病突发的风险。研究者
建立了一个人工智能模型来完成这一评估。该模型基于大样本
数据（160万名患者的440万次医保就诊记录），并且使用了
2400多个变量，有如此大的数据量，该模型应该可以突破客观
无知的限制。
不出所料，该人工智能模型的准确性明显超过临床医生。
若想进一步评估该模型的预测性能，请你想一下，如果对那些
被模型判定为具有最高发病风险（前10%）的患者进行检查，并
发现其中有30%的人确实会突发心脏病，而那些被模型判定为具
有中等发病风险的患者中，只有9.3%的人突发了心脏病，我们
就可以据此推论，医生的表现受限于客观无知的程度，至少与
其受限于判断力不足的程度相差无几。
否 认 无 知 是 无 知 的另 一 种 诱 导
完美预测是不可能实现的，这似乎是显而易见的事。当
然，断言未来是不可预测的也算不上什么具有突破性的见解。
然而，众多研究证据都表明，人们做预测时会过分自信，这说
明很多时候这一显而易见的事实被我们忽视了。
过分自信的普遍性让我们对非正式调查中那些相信直觉的
决策者有了新看法。我们发现，人们经常错误地将自信水平这一主观指标当成预测有效性的指标。例如，在第9章中，看完有
关娜塔莉和莫妮卡的信息后，你做出了与信息相一致的判断，
这时内部信号就会使你确信娜塔莉是更优的候选人。如果你对
你的预测充满信心，你就已经陷入了效度错觉中： 仅 通 过 你 所
获取 的 信 息 进 行 预 测 ， 其 准 确 性 必 然 非 常 低 。
那些对自己的判断极度自信的人否认自己的判断中存在噪
声和偏差。他们不仅认为自己优于常人，甚至认为自己可以对
一些实际上不可预测的事件进行预测。也就