关系数为
0.15（PC=55%），并且肯定与交叉验证后的回归模型非常相
似，也不需要任何你没有的数据或任何复杂的计算。
用道斯的话说，均等权重模型具有“稳定之美”。研究判
断的学生已对这句话达成共识。介绍这一观点的开创性文章的
最后一句话给出了另一个精妙的总结：“应用均等权重模型所
需的全部技巧是决定要关注哪些变量，并知道如何将这些变量
进行叠加 。”
更 简 捷 ： 简 约 模 型
另一种简化的方式是采用简约模型（frugal models）或简
单规则。简约模型是对现实进行极端简化并无须复杂计算的模
型，但在某些情况下，它们可以产生令人惊叹的预测效果。
令很多人感到惊讶的是，这些模型是基于多元回归的一个
特征建立的。假设你使用了两个准确性很高的预测因素，它们
与结果的相关系数分别为0.6（PC=71%）和0.55（PC=69%），且
这两个预测因素彼此相关，相关系数为0.5。当将这两个预测因
素进行最佳组合时，预测的准确性会有多好呢？答案令人失
望，相关系数是0.67（PC=73%），这个结果比之前好，但并没
有好太多。
该示例说明了一条一般性规则：将两个或多个相关预测因
素组合后，预测效果相比于单个预测因素并不会好多少。因为在现实生活中，预测因素几乎总是相关的，所以这一统计事实
支持使用包含少量预测因素的简约模型进行预测。与使用很多
预测因素的模型相比，简单规则只需少量计算或根本无须计
算，就能在某些情况下达到令人吃惊的预测效果。
一个研究团队于2020年发表了一项研究成果。他们将简约
模型应用于一系列现实问题，内容包括在案件待审期间法官是
否该批准被告的保释申请。这项决策隐含着对被告行为的预
测，如果错误地拒绝保释，被告将被不必要地拘押，从而对个
人和社会造成巨大损失；如果错误地批准保释，则被告可能在
受审前逃脱，甚至犯下其他罪行。
研究人员仅使用两个可高度预测被告在保释期逃脱可能性
的已知变量来建立模型：被告的年龄（年龄越大，逃脱风险较
低）和未按时出庭受审的次数（有未按时出庭受审记录的人，
更可能逃脱）。该模型将这两个变量转换为一系列分数，并针
对风险进行评分，在计算被告保释期逃脱的风险时无须使用计
算机，甚至不需要计算器。
当用真实数据来测试时，该简约模型的表现与那些使用众
多变量的统计模型一样好，而在预测逃脱风险方面，简约模型
比几乎所有法官的判断都要好。同样的简约模型采用少数几个
整数（-3～+3）对最多5个特征进行评分，并以此来对各种任务
进行预测，如基于乳房X线片判断肿瘤的严重程度、诊断心脏
病、预测信用风险等。在所有这些任务中，简约模型的表现都
与复杂回归模型一样好，只不过它通常不如机器学习模型的表
现好。另一项研究也证明了简约模型的有效性。另外一个研究小
组研究了一个与上述案例相似但有所不同的司法问题：预测惯
犯。研究人员在评估被告再次犯罪的风险时，使用的模型只有
两个输入变量，但该模型的预测效果与使用137个变量的模型相
同。毫无疑问，这两个预测因素（年龄和先前被定罪的次数）
与保释模型中使用的两个因素密切相关，而大量证据表明，它
们与犯罪行为也是紧密相关的 。
简约模型的吸引力在于其透明性和易用性，而且相比于其
他复杂模型，它只需略微牺牲一点准确性就能获得这些优势。
更 复 杂 ： 机 器 学 习
在旅程的第二部分，让我们在复杂性频谱上朝相反的方向
前进。如果我们可以使用更多预测因素，收集更多数据，发现
前人未发现的关系模式，并对这些模式进行建模以实现更好的
预测效果，那会如何呢？从本质上讲，这就是人工智能的目
的。
海量数据集对复杂分析至关重要。而获得此类数据集越来
越容易，是近年来人工智能快速发展的主要原因之一。例如，
大型数据集可以机械地处理“断腿的例外”（broken-leg
exceptions ）这种情况。这个有点神秘的短语可以追溯到前文
中梅尔假想的一个示例：设想有这样一个模型，它可以预测人
们今晚去看电影的可能性，无论你对该模型有多大信心，如果你碰巧知道某人刚摔断了腿，你都可能会比模型更准确地预测
他今晚是否会去看电影。
在使用简单模型时，“断腿原则”给决策者提供了重要启
示：它告诉人们何时需推翻模型，何时则不需要这样做。如果
你掌握了模型未考虑的如“断腿”这样的决定性信息，你就应
该推翻模型的建议。此外，即使你缺少此类信息，有时你也不
会同意模型的建议。在这种情况下，你试图推翻模型的行为，
反映了你对相同预测因素做出反应的个人模式。这种个人模式
很可能是无效的，你的干预可能会降低预测的准确性，因此你
应该避免推翻模型。
机 器 学 习 模 型 之 所 以 能 够 在 预 测 方 面 表 现 出 色 ， 其 中 一 个
原 因 就 是 ， 它 们 能 够 发 现 人 类 所 无 法 想 象 的 各 种 “ 断 腿 ” 情
况 。在具有大量案例、海量数据的条件下，追踪观影行为的模
型真的会学习，例如在固定观影日去了医院的人当晚不太可能
去看电影。可以说，以这种方式改进对不常见事件的预测，可
减少对人工监督的需求。
人工智能不是魔法，也不需要理解什么，它仅仅是在识别
模式。虽然我们必须佩服机器学习的力量，但我们也要明白，
人工智能可能要花很长时间才能理解为什么断腿之人会错过电
影之夜。
更 明 智 的 保 释 决 策在前面提到的研究团队将简单规则应用于保释决策问题的
同时，由塞德希尔·穆来纳森（Sendhil Mullainathan ）(6)领
导的另一个团队训练了复杂的人工智能模型来执行相同的任
务。研究团队获得了更大的数据集——包含758 027个保释裁定
的案例库。对于每种情况，研究团队可以获得和法官一样的信
息：被告的罪行、犯罪记录、未按时出庭受审的次数等。除年
龄外，参与训练的算法没有其他任何人口统计学信息适合使
用。对于每一起案件，研究人员还知道关于被告是否被释放，
以及他如果被释放，之后是否会按时出庭或被重新逮捕（被告
中有74%的人获得保释，其中15%的人在那之后没有按时出庭，
26%的人则被重新逮捕）的信息。研究人员利用这一数据来训练
一个机器学习算法，并评估了该算法的表现。该模型是通过机
器学习构建的，因此并不限于线性组合。如果它在数据中检测
到更复杂的规律，它就会使用此模式来改进预测。
该模型用于预测嫌疑人在保释期逃脱的风险，因此将风险
量化为数字，而非只产生是否准予保释的决定。这种方法确定
了最大可接受风险的阈值，即如果风险高于该阈值，就应该拒
绝保释。然而，研究人员发现，无论如何设置风险阈值，使用
该模型的预测得分都高于法官的预测。穆来纳森的团队计算得
出，如果将风险阈值设置为一个值，使模型预测的拒绝保释人
数与法官判决的拒绝保释人数相同，则犯罪率最多可降低24%，
个中原因在于，被关押的人最有可能再次犯罪。相反，如果将
风险阈值设置为使该模型在不提高犯罪率的情况下，尽可能减
少被拒绝保释的人数，则研究人员计算得出，被羁押的人数最多可再减少42%。换句话说，机器学习模型在预测哪些被告属于
犯罪高风险人群方面，表现要比法官好得多。
利用机器学习建立的模型，也比使用相同信息的线性模型
成功得多，原因很有趣：机器学习算法在变量组合中发现了一
些会被线性模型遗漏的重要信息。算法能对风险最高的被告进
行归类，就证明它有能力找到很容易被其他模型忽略的模式。
换句话说，数据中的某些模式尽管很少见，却非常准确地预测
出了高风险人群。利用算法找到罕见但具有决定性作用的模
式，让我们想起了“断腿”的概念。
研究人员还使用该算法为每位法官构建了模型，类似于我
们在第9章中描述的判断模型（但不限于简单线性组合）。他们
将这些模型应用于整个数据集，使团队能够模拟法官在遇到相
同案件时可能做出的判决，并比较这些判决。结果表明，保释
裁定中存在相当大的系统噪声，其中一些是水平噪声：根据宽
容程度对法官进行分类时，20%最宽容的法官（即保释率最高的
前20%的法官）准予保释的概率为83%，而20%最严厉的法官准予
保释的概率为61%。法官对于哪些被告具有较高逃脱风险的判断
方式也大不相同，被一位法官视为具有低逃脱风险的被告，可
能被另一位更严厉的法官视为具有高逃脱风险。这些结果为模
式噪声提供了清晰的证据。更详细的分析表明，案例之间的变
异占总变异的67%，系统噪声占33%。系统噪声包括一些水平噪
声，即平均严厉程度之间的差异，但其中大多数（79%）是模式
噪声。幸好，机器学习程序的高准确性并不以牺牲法官追求的其
他目标，如种族平等为代价。从理论上讲，尽管该算法不使用
种族相关数据，但它也可能会无意间加剧种族歧视。如果模型
使用与种族信息高度相关的预测因素（如邮政编码），或是用
于算法训练的数据源暗含偏见，则可能会出现种族歧视。例
如，如果将过去的逮捕次数作为预测因素，而过去的逮捕次数
受到种族歧视的影响，那么得到的算法也会存在歧视问题。
尽管从原则上讲，这种歧视无疑是一种风险，但在一些重
要层面，该算法所做出的决策比法官群体中存在的种族歧视要
轻微。例如，如果通过设置风险阈值使犯罪率与法官判决的犯
罪率相同，则该算法可将有色人种被判入狱的概率减少41%。在
其他情况下，算法也得出了类似的结果，即提高准确性不必以
加剧种族歧视为代价。正如研究小组所指出的：通过训练，该
算法很容易用于减少种族歧视。
另一项不同领域的研究阐述了算法如何在提高准确性的同
时减少歧视。哥伦比亚商学院教授博·考吉尔（Bo Cowgill）
考察了一家大型科技公司招聘软件工程师的情况。考吉尔并未
使用人工筛选简历的方式来筛选可进入面试流