状态
的影响，而模型并不会。这些判断的噪声带来的误差很可能与任何事物都不相关，这意味着在大多数情况下，我们可以将其
视为随机误差。
从你的判断中消除噪声通常会提高你的预测准确性。例
如，假设你的预测与结果的相关系数是0.5（PC=67%），此时你
的判断中包含了50%由噪声导致的变异，而如果你的判断没有噪
声，那么它们与结果的相关系数将提升至0.71（PC=75%）。由
此可见， 用 机 器 减 少 噪 声 可 以 提 高 预 测 判 断 的 有 效 性 。
简而言之，用模型代替人类的判断意味着两件事：消除了
人类的复杂规则，消除了噪声。判断模型比判断更有效这一强
有力的发现说明：从人类判断的复杂规则中获得的好处（如果
存在的话）不足以补偿噪声所带来的损失。 你 可 能 会 认 为 自 己
比 一 般 人 更 擅 长 思 考 、 更 有 洞 察 力 ， 但 实 际 上 只 是 你 的 噪 声 更
多 而 已 。
为什么我们以为复杂的规则更有效，实际上它们却损害了
判断的准确性呢？一方面，人们发明的许多复杂规则并不正
确；另一方面，即使复杂规则在原则上是有效的，它们也不可
避免地仅适用于少数能被观察到的情况。例如，假设你已经得
出结论：对于一个独创性极高的候选人，即使他在其他方面得
分一般，也值得被雇用。可问题在于，从定义上看，具有独创
性的候选人总是很稀缺。既然对独创性的评估可能不可靠，在
这一指标上得了高分的人就可能是侥幸，而真正具有独创性的
人才往往无法被发现。即使在绩效评估中具有较高独创性的候
选人最终真的表现得特别优秀，绩效评估本身也存在很多问
题。两端的测量误差会不可避免地削弱预测的有效性，一些小概率事件尤其可能被忽略，复杂模型的优势很快就会被测量误
差所掩盖。
马丁·于（Martin Yu）和内森·昆塞尔（Nathan
Kuncel）报告了一项比戈德堡所做的更激进的研究。该研究基
于莫妮卡和娜塔莉的案例，使用了一家跨国咨询公司的数据，
这家跨国咨询公司聘请专家评估了3个独立样本中共847名高管
职位的候选人。专家们在7个不同的评估维度上对这些候选人进
行了评分，并使用他们的诊断性判断为每位候选人生成了一个
预测总分，然而结果令人大吃一惊。
马丁·于和昆塞尔将判断结果与随机线性模型进行比较，
而非与他们的最佳简单模型进行比较。他们为7个预测因素生成
了10 000套随机权重，并应用了这10 000个随机公式来预测工
作绩效。他们吃惊地发现，用任何线性模型来对所有案例进行
预测，其结果均优于人类基于相同信息所做出的判断。在其中
一个样本中，10 000个随机加权线性模型中有77%优于人类专
家；在另外两个样本中，随机模型100%胜过人类专家。换句话
说，该研究表明，所有简单模型的表现都比人类专家好。
这项研究得出的结论比我们从戈德堡的判断模型中得出的
结论更有力。事实上，这是个非常极端的例子。在这种情况
下，人类的判断确实非常糟糕，这就解释了为什么即使是不尽
如人意的线性模型，其表现也超越了人类判断。当然，我们并
不能因此下结论说机器绝对比人强，尽管如此，机械地遵守简
单规则（马丁·于和昆塞尔称其为“无意识的一致性”（mindless consistency ））可以显著提高针对困难问题所做
判断的品质，这一事实说明了噪声对诊断性预测的巨大影响。
本章简要地说明了噪声对诊断性判断造成的负面影响。在
预测性判断中，人类专家很容易被简单的公式所击败，其中包
括真实模型、判断模型甚至随机生成的模型。这一发现支持我
们使用无噪声的方法——规则和算法，这也是下一章的主题。·　 消 除 噪 声
判 断 中 存 在 噪 声 ， 但 判 断 模 型 中 没 有
·　人们往往相信自己的判断能更好地考虑问题的复
杂性和微妙的细节，但复杂性和微妙的细节基本上没什么
用，因为它们并不会提升简单模型的准确性。
·　在保罗·梅尔的书出版60多年后的今天，机械性
预测优于人类的判断这一观点仍然令人震惊。
·　判断中有很多噪声，因此无噪声的判断模型会做
出更准确的预测。第 10章
无 噪 声 的 规 则
近年来，人工智能（Artificial Intelligence ）特别是机
器学习技术让机器能够执行许多以前只有人类才能执行的任
务。机器学习算法可以承担人脸识别、语言翻译、分析医学影
像等任务，并且可以以惊人的速度和准确性来处理计算问题，
例如为成千上万名驾驶员迅速规划行车路线。它们还可以执行
困难的预测任务：预测美国最高法院的判决；识别哪些嫌疑人
更可能在保释期逃脱；评估儿童保护部门接到的哪些电话更紧
急，并需要工作人员上门访视。
图像
尽管如今我们一听到“算法”一词，首先想到的是上面这
些应用，但这个词还有更广泛的含义。在词典中，算法的定义
是：在解决计算或其他问题时（尤其是借助计算机）所遵循的
步骤或规则。根据这一定义，我们在上一章中所描述的简单模
型和其他形式的机械性判断也属于算法。
事实上，从简单的规则到最复杂且难以理解的机器学习算
法，许多机械性方法都可以胜过人类的判断。机械性方法之所
以有这种出色表现，一个关键原因可能是所有机械性方法均无
噪声，尽管这不是唯一的原因。为了研究不同类型的基于规则的方法，并了解每种方法为
何以及在何种条件下更有价值，我们从第9章的基于多元回归的
简单模型（即线性回归模型）开始我们的旅程。由此出发，我
们将在复杂性频谱上朝着两个相反的方向前进，首先从极端简
捷的一端开始，然后朝着逐渐复杂的方向前进（见图10-1）。
图 1 0 - 1　 4类 规 则 和 算 法 的 相 对 复 杂 性
简 捷 ： 稳 定 之 美
罗宾·道斯（Robyn Dawes）是20世纪六七十年代美国俄勒
冈州尤金市研究人类判断行为的团队中的另一位明星成员。
1974年，道斯在简化预测任务方面取得了突破。他的研究思路
令人惊讶：他建议不要使用多元回归模型来确定每个预测因素
的精确权重，而应给所有预测因素分配均等的权重。
道斯将均等权重的公式定义为“非最适线性模型
（improper linear model）。他出人意料地发现，这些均等权
重模型（equal-weight models）的准确性与合适的回归模型差
不多，且远胜于诊断性判断 。
连“并非最合适的模型”的支持者也承认，这种说法是不
可信的，并且与统计直觉相悖。的确，道斯及其助手伯纳德·科里根（Bernard Corrigan ）最初曾努力将论文发表在学术期
刊上，但是编辑们根本不认同。如果回顾一下上一章中的莫妮
卡和娜塔莉的例子，你就会相信某些预测因素比其他预测因素
更重要。例如，相比于职业技能，大多数人会给予领导力更高
的权重。因此，简单的未加权平均值怎么可能比精细加权的平
均值或专家判断更好地预测一个人的表现呢？
在道斯取得研究突破多年后的今天，人们已经很熟悉这种
令其同时代人惊讶的统计现象。正如前文所解释的那样，多元
回归模型计算出了最佳权重，从而使均方误差最小化，而多元
回归使原始数据中的误差最小化，因此，公式会自行调整以便
预测数据中的每个偶然因素。例如，如果样本中包含一些具有
较高职业技能但是由于不相关原因而表现异常出色的经理，该
模型就将增加职业技能的权重。
这其中的挑战是：当将公式应用于样本之外时，也就是用
它预测不同数据集的结果时，这些权重将不再是最优的。原始
样本中的偶然因素不再存在，因为它们是“偶然因素”。在新
样本中，具有较高职业技能的经理并不会都表现出色，而且新
样本中具有原公式无法预测的新因素。要衡量模型预测的准确
性，正确的做法是观察它在新样本中的表现，也就是观察它的
“交叉验证相关性”（cross-validated correlation ）。事实
上，回归模型在原始样本上过于出色，因此交叉验证相关性的
表现几乎总是比它在原始样本中的表现差。道斯和科里根在几
种情况下对均等权重模型和多元回归模型（交叉验证后）进行
了比较。他们采用的一个案例就是预测伊利诺伊大学90名心理学研究生第一年的GPA，使用的是与学业成就相关的10个变量，
如能力测试分数、大学成绩、各种同龄人评分（peer
ratings，如外向性）以及各种自评（如责任心）等。标准多元
回归模型的预测相关系数为0.69，经过交叉验证后降至
0.57（PC=69%）；均等权重模型与第一年GPA预测的相关系数与
此大致相同，为0.6（PC=71%）。许多其他研究也得到了相似的
结果。
当原始样本较小时，经过交叉验证后，准确性会降低更
多，因为小样本的偶然性多，变异性较大。道斯指出，社会科
学研究中通常使用小样本，以致所谓的最佳权重的优势消失殆
尽。正如统计学家霍华德·怀纳（Howard Wainer）在一篇研究
最适当权重估值的学术论文中所使用的副标题：它并不重要。
用道斯的话说，“我们不需要比我们的测量更精确的模型”。
均等权重模型之所以表现出色，是因为它不容易受样本中偶然
因素的影响。
道斯的研究的直接理论成果值得广为人知：即使你缺少有
关结果先前的数据，你也可以进行有效的统计预测，只需收集
一些你认为与预测结果相关的预测因素即可。
假设你必须对已经在多个维度上获得评分的高管的绩效做
出预测，如第9章中高管的例子所示。你相信这些评分有很强的
预测力，但是你没有每个评分预测的准确性数据。你也不可能
花费几年的时间来追踪大量管理人员的绩效情况，但是，你可
以基于这7个评分的均等权重模型来做预测。那么，这个均等权
重模型的预测效果如何呢？它与结果的相关系数将为0.25（PC=58%），远优于诊断性预测——相